{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sift Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para os arquivos\n",
    "logo_path = \"../target/logo_target.png\"\n",
    "video_path = '../videos/15s-canto-direito-rotacionada.mp4'\n",
    "print(video_path)\n",
    "\n",
    "# Carregar a logotipo target\n",
    "logo_image = cv2.imread(logo_path, cv2.IMREAD_GRAYSCALE)\n",
    "if logo_image is None:\n",
    "    raise IOError(\"Não foi possível carregar a imagem da logotipo.\")\n",
    "\n",
    "# Iniciar a captura de vídeo\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Não foi possível abrir o vídeo.\")\n",
    "\n",
    "# Inicializar SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Encontrar keypoints e descritores na logotipo\n",
    "kp_logo, des_logo = sift.detectAndCompute(logo_image, None)\n",
    "\n",
    "# Configurar o FLANN Matcher\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)  # Número de verificações\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# Parâmetros de detecção\n",
    "MIN_MATCH_COUNT = 10  # Número mínimo de correspondências para considerar uma detecção\n",
    "logo_present = False\n",
    "start_time = None\n",
    "end_time = None\n",
    "detections = []\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Fim do vídeo\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar keypoints e descritores no frame\n",
    "    kp_frame, des_frame = sift.detectAndCompute(frame_gray, None)\n",
    "\n",
    "    if des_frame is not None:\n",
    "        # Encontrar correspondências usando FLANN\n",
    "        matches = flann.knnMatch(des_logo, des_frame, k=2)\n",
    "\n",
    "        # Aplicar o ratio test de Lowe\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.7 * n.distance:\n",
    "                good_matches.append(m)\n",
    "\n",
    "        if len(good_matches) > MIN_MATCH_COUNT:\n",
    "            # Encontrou a logotipo no frame\n",
    "            if not logo_present:\n",
    "                logo_present = True\n",
    "                start_time = frame_count / fps\n",
    "        else:\n",
    "            if logo_present:\n",
    "                logo_present = False\n",
    "                end_time = frame_count / fps\n",
    "                detections.append({\n",
    "                    \"start\": str(timedelta(seconds=start_time)),\n",
    "                    \"end\": str(timedelta(seconds=end_time))\n",
    "                })\n",
    "    else:\n",
    "        if logo_present:\n",
    "            logo_present = False\n",
    "            end_time = frame_count / fps\n",
    "            detections.append({\n",
    "                \"start\": str(timedelta(seconds=start_time)),\n",
    "                \"end\": str(timedelta(seconds=end_time))\n",
    "            })\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Se o vídeo terminar com a logotipo presente\n",
    "if logo_present:\n",
    "    end_time = frame_count / fps\n",
    "    detections.append({\n",
    "        \"start\": str(timedelta(seconds=start_time)),\n",
    "        \"end\": str(timedelta(seconds=end_time))\n",
    "    })\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Salvar em um arquivo JSON\n",
    "output = {\"detections\": detections}\n",
    "#with open('detecoes_logo.json', 'w') as json_file:\n",
    "    #json.dump(output, json_file, indent=4)\n",
    "\n",
    "#print(\"Detecções salvas em 'detecoes_logo.json'.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = {'start': detections[0]['start'], 'end': detections[-1]['end']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import timedelta\n",
    "\n",
    "def detectar_logo_no_video2(video_path, logo_path, output_frame_path, min_match_count=10, ratio_test=0.7):\n",
    "    \"\"\"\n",
    "    Detecta a presença de uma logotipo em um vídeo e salva o primeiro frame onde a logo foi detectada.\n",
    "    Retorna os timestamps de aparição e desaparecimento.\n",
    "\n",
    "    :param video_path: Caminho para o arquivo de vídeo.\n",
    "    :param logo_path: Caminho para a imagem da logotipo target.\n",
    "    :param output_json_path: Caminho para salvar o arquivo JSON com os resultados.\n",
    "    :param output_frame_path: Caminho para salvar o primeiro frame onde a logotipo foi detectada.\n",
    "    :param min_match_count: Número mínimo de correspondências para considerar uma detecção.\n",
    "    :param ratio_test: Valor do ratio test de Lowe para filtrar correspondências.\n",
    "    \"\"\"\n",
    "    # Carregar a logotipo target em escala de cinza\n",
    "    logo_image = cv2.imread(logo_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if logo_image is None:\n",
    "        raise IOError(\"Não foi possível carregar a imagem da logotipo.\")\n",
    "\n",
    "    # Iniciar a captura de vídeo\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Não foi possível abrir o vídeo.\")\n",
    "\n",
    "    # Inicializar o detector SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detectar keypoints e descritores na logotipo\n",
    "    kp_logo, des_logo = sift.detectAndCompute(logo_image, None)\n",
    "    if des_logo is None:\n",
    "        raise ValueError(\"Não foi possível encontrar descritores na logotipo.\")\n",
    "\n",
    "    # Configurar o FLANN Matcher\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)  # Número de verificações\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # Parâmetros de detecção\n",
    "    logo_present = False\n",
    "    start_time = None\n",
    "    end_time = None\n",
    "    detections = []\n",
    "    frame_saved = False  # Verifica se o primeiro frame já foi salvo\n",
    "\n",
    "    # Obter frames por segundo (FPS) do vídeo\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps == 0:\n",
    "        raise ValueError(\"FPS do vídeo é 0, verifique o arquivo de vídeo.\")\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Fim do vídeo\n",
    "\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar keypoints e descritores no frame\n",
    "        kp_frame, des_frame = sift.detectAndCompute(frame_gray, None)\n",
    "\n",
    "        if des_frame is not None:\n",
    "            # Encontrar correspondências usando FLANN\n",
    "            try:\n",
    "                matches = flann.knnMatch(des_logo, des_frame, k=2)\n",
    "            except cv2.error as e:\n",
    "                print(f\"Erro durante a correspondência de características: {e}\")\n",
    "                matches = []\n",
    "\n",
    "            # Aplicar o ratio test de Lowe\n",
    "            good_matches = []\n",
    "            for m_n in matches:\n",
    "                if len(m_n) != 2:\n",
    "                    continue\n",
    "                m, n = m_n\n",
    "                if m.distance < ratio_test * n.distance:\n",
    "                    good_matches.append(m)\n",
    "\n",
    "            if len(good_matches) > min_match_count:\n",
    "                # Encontrou a logotipo no frame\n",
    "                if not logo_present:\n",
    "                    logo_present = True\n",
    "                    start_time = frame_count / fps\n",
    "\n",
    "                    # Salvar o primeiro frame onde a logotipo foi detectada\n",
    "                    if not frame_saved:\n",
    "                        cv2.imwrite(output_frame_path, frame)\n",
    "                        frame_saved = True\n",
    "                        print(f\"Primeiro frame salvo em '{output_frame_path}'.\")\n",
    "\n",
    "            else:\n",
    "                if logo_present:\n",
    "                    logo_present = False\n",
    "                    end_time = frame_count / fps\n",
    "                    detections.append({\n",
    "                        \"start\": str(timedelta(seconds=start_time)),\n",
    "                        \"end\": str(timedelta(seconds=end_time))\n",
    "                    })\n",
    "        else:\n",
    "            if logo_present:\n",
    "                logo_present = False\n",
    "                end_time = frame_count / fps\n",
    "                detections.append({\n",
    "                    \"start\": str(timedelta(seconds=start_time)),\n",
    "                    \"end\": str(timedelta(seconds=end_time))\n",
    "                })\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Se o vídeo terminar com a logotipo presente\n",
    "    if logo_present:\n",
    "        end_time = frame_count / fps\n",
    "        detections.append({\n",
    "            \"start\": str(timedelta(seconds=start_time)),\n",
    "            \"end\": str(timedelta(seconds=end_time))\n",
    "        })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Estruturar o resultado\n",
    "    output = {\"detections\": detections}\n",
    "\n",
    "    # Salvar em um arquivo JSON\n",
    "    #with open(output_json_path, 'w') as json_file:\n",
    "        #json.dump(output, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo_path = \"../target/logo_target.png\"\n",
    "video_path = '../videos/15s-canto-esquerdo-pequeno.mp4'\n",
    "detectar_logo_no_video2(video_path, logo_path, 'frame_to_mask_canto_esquerdo_pequeno.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def detectar_logo_com_sift_e_mascara(video_path, logo_path, mask_path, min_match_count=10):\n",
    "    # Inicializar SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Carregar o template (logo) e sua máscara\n",
    "    logo = cv2.imread(logo_path, 0)\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "\n",
    "    # Detectar keypoints e descritores na logo usando a máscara\n",
    "    kp_logo, des_logo = sift.detectAndCompute(logo, mask)\n",
    "\n",
    "    # Configurar FLANN para correspondência de keypoints\n",
    "    index_params = dict(algorithm=1, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # Carregar vídeo\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_count = 0\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Obter a taxa de frames por segundo do vídeo\n",
    "\n",
    "    logo_present = False\n",
    "    logo_detected = False\n",
    "    detections = []\n",
    "    start_time = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar keypoints e descritores no frame atual\n",
    "        kp_frame, des_frame = sift.detectAndCompute(frame_gray, None)\n",
    "\n",
    "        if des_frame is not None:\n",
    "            # Correspondência de descritores\n",
    "            matches = flann.knnMatch(des_logo, des_frame, k=2)\n",
    "\n",
    "            # Aplicar ratio test para selecionar boas correspondências\n",
    "            good_matches = []\n",
    "            for m, n in matches:\n",
    "                if m.distance < 0.75 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "\n",
    "            # Se o número de boas correspondências for suficiente, considerar que a logo foi detectada\n",
    "            if len(good_matches) > min_match_count:\n",
    "                if not logo_present:\n",
    "                    logo_present = True\n",
    "                    start_time = frame_count / fps\n",
    "\n",
    "                logo_detected = True\n",
    "            else:\n",
    "                if logo_present and logo_detected:\n",
    "                    # A logo desapareceu\n",
    "                    end_time = frame_count / fps\n",
    "                    detections.append({\n",
    "                        \"start\": start_time,\n",
    "                        \"end\": end_time\n",
    "                    })\n",
    "                    logo_present = False\n",
    "                    logo_detected = False\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Caso a logo esteja presente até o final do vídeo, adicionar a última detecção\n",
    "    if logo_present and logo_detected:\n",
    "        end_time = frame_count / fps\n",
    "        detections.append({\n",
    "            \"start\": start_time,\n",
    "            \"end\": end_time\n",
    "        })\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 5.0, 'end': 5.6}, {'start': 5.633333333333334, 'end': 5.666666666666667}, {'start': 5.733333333333333, 'end': 5.766666666666667}, {'start': 5.8, 'end': 6.766666666666667}, {'start': 6.8, 'end': 6.833333333333333}, {'start': 6.933333333333334, 'end': 6.966666666666667}, {'start': 7.1, 'end': 7.166666666666667}, {'start': 7.4, 'end': 7.433333333333334}, {'start': 7.466666666666667, 'end': 7.633333333333334}, {'start': 7.8, 'end': 7.833333333333333}, {'start': 8.633333333333333, 'end': 8.8}, {'start': 8.833333333333334, 'end': 8.9}, {'start': 8.933333333333334, 'end': 8.966666666666667}, {'start': 9.0, 'end': 9.066666666666666}, {'start': 9.1, 'end': 9.133333333333333}, {'start': 14.5, 'end': 14.6}]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "video_path = '../videos/15s-canto-direito-rotacionada.mp4'\n",
    "logo_path = \"../target/logo_target.png\"\n",
    "mask_path = '/masks/mask_canto_direito_rotacionada.png'\n",
    "\n",
    "result = detectar_logo_com_sift_e_mascara(video_path, logo_path, mask_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 4.266666666666667, 'end': 9.833333333333334}\n"
     ]
    }
   ],
   "source": [
    "detection = {'start': result[0]['start'], 'end': result[-1]['end']}\n",
    "print(detection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
